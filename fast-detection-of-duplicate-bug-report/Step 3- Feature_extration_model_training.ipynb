{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cj0uxaDyXPoY"
   },
   "source": [
    "# **Feature Extraction Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "id": "xm0lbbfSFw_n",
    "outputId": "d5b1c6ff-83e8-4edf-ba26-c080b5327ba2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\niranjans3ln\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\niranjans3ln\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import numpy as np\n",
    "from gensim import corpora,models\n",
    "import time\n",
    "import pickle\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "hyhp-dKUHEed",
    "outputId": "6ac21a34-1db1-4aef-96ed-95c0c24299d3"
   },
   "outputs": [],
   "source": [
    "# open a file, where you stored the pickled data\n",
    "f = open('dataset/bow_corpus.pickle', 'rb')\n",
    "bow_corpus=pickle.load(f)\n",
    "\n",
    "file = open('dataset/dictionary.pickle', 'rb')\n",
    "dictionary=pickle.load(file)\n",
    "\n",
    "# later on, load trained model from file\n",
    "lda_model =  models.LdaModel.load('dataset/lda_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Dm8jFprLADw"
   },
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 5:\n",
    "            result.append(lemmatize(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wpCTWfbzK8sa"
   },
   "outputs": [],
   "source": [
    "#Import all the clusters from the drive \n",
    "for c in range(10):\n",
    "  exec('topic_{} = pd.read_csv(\"dataset/topic_{}.csv\")'.format(c,c))\n",
    "  exec(\"topic_{}= topic_{}.drop(columns=['Unnamed: 0'])\".format(c,c))\n",
    "  exec(\"topic_{}['Description'] = topic_{}['Description'].map(preprocess)\".format(c,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oiZ93ze1VI6_"
   },
   "outputs": [],
   "source": [
    "#creating a corpus for Word2Vec and FastText models\n",
    "for i in range(10):\n",
    "  exec('sent_{} = []'.format(i))\n",
    "  exec('x= topic_{}'.format(i))\n",
    "  for j in range(len(x)):\n",
    "    exec('sent_{}.append(topic_{}.Description[{}])'.format(i,i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "colab_type": "code",
    "id": "yyBtELSBhZkw",
    "outputId": "6a439bb7-80fb-487a-dd17-3be924f4f6b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n",
      "104\n",
      "114\n",
      "123\n",
      "94\n",
      "111\n",
      "49\n",
      "79\n",
      "94\n",
      "142\n"
     ]
    }
   ],
   "source": [
    "#Length of all the corpus\n",
    "for sent in range(10):\n",
    "  exec('print(len(sent_{}))'.format(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MN3B8FMcFRJ",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting glove_python\n",
      "  Downloading glove_python-0.1.0.tar.gz (263 kB)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from glove_python) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from glove_python) (1.7.3)\n",
      "Building wheels for collected packages: glove-python\n",
      "  Building wheel for glove-python (setup.py): started"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\niranjans3ln\\\\AppData\\\\Local\\\\Temp\\\\pip-install-ydr7ifc7\\\\glove-python_967621288cb94b3389cdbf0335aa4ca8\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\niranjans3ln\\\\AppData\\\\Local\\\\Temp\\\\pip-install-ydr7ifc7\\\\glove-python_967621288cb94b3389cdbf0335aa4ca8\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\niranjans3ln\\AppData\\Local\\Temp\\pip-wheel-qzmslhgh'\n",
      "       cwd: C:\\Users\\niranjans3ln\\AppData\\Local\\Temp\\pip-install-ydr7ifc7\\glove-python_967621288cb94b3389cdbf0335aa4ca8\\\n",
      "  Complete output (14 lines):\n",
      "  C:\\Anaconda3\\lib\\site-packages\\setuptools\\dist.py:757: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "    warnings.warn(\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.9\n",
      "  creating build\\lib.win-amd64-3.9\\glove\n",
      "  copying glove\\corpus.py -> build\\lib.win-amd64-3.9\\glove\n",
      "  copying glove\\glove.py -> build\\lib.win-amd64-3.9\\glove\n",
      "  copying glove\\__init__.py -> build\\lib.win-amd64-3.9\\glove\n",
      "  running build_ext\n",
      "  building 'glove.glove_cython' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for glove-python\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\niranjans3ln\\\\AppData\\\\Local\\\\Temp\\\\pip-install-ydr7ifc7\\\\glove-python_967621288cb94b3389cdbf0335aa4ca8\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\niranjans3ln\\\\AppData\\\\Local\\\\Temp\\\\pip-install-ydr7ifc7\\\\glove-python_967621288cb94b3389cdbf0335aa4ca8\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' clean --all\n",
      "       cwd: C:\\Users\\niranjans3ln\\AppData\\Local\\Temp\\pip-install-ydr7ifc7\\glove-python_967621288cb94b3389cdbf0335aa4ca8\n",
      "  Complete output (8 lines):\n",
      "  C:\\Anaconda3\\lib\\site-packages\\setuptools\\dist.py:757: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "    warnings.warn(\n",
      "  usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n",
      "     or: setup.py --help [cmd1 cmd2 ...]\n",
      "     or: setup.py --help-commands\n",
      "     or: setup.py cmd --help\n",
      "  \n",
      "  error: option --all not recognized\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed cleaning build dir for glove-python\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\niranjans3ln\\\\AppData\\\\Local\\\\Temp\\\\pip-install-ydr7ifc7\\\\glove-python_967621288cb94b3389cdbf0335aa4ca8\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\niranjans3ln\\\\AppData\\\\Local\\\\Temp\\\\pip-install-ydr7ifc7\\\\glove-python_967621288cb94b3389cdbf0335aa4ca8\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\niranjans3ln\\AppData\\Local\\Temp\\pip-record-hcior3be\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Anaconda3\\Include\\glove-python'\n",
      "         cwd: C:\\Users\\niranjans3ln\\AppData\\Local\\Temp\\pip-install-ydr7ifc7\\glove-python_967621288cb94b3389cdbf0335aa4ca8\\\n",
      "    Complete output (10 lines):\n",
      "    C:\\Anaconda3\\lib\\site-packages\\setuptools\\dist.py:757: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "      warnings.warn(\n",
      "    running install\n",
      "    C:\\Anaconda3\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "      warnings.warn(\n",
      "    running build\n",
      "    running build_py\n",
      "    running build_ext\n",
      "    building 'glove.glove_cython' extension"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Building wheel for glove-python (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for glove-python\n",
      "Failed to build glove-python\n",
      "Installing collected packages: glove-python\n",
      "    Running setup.py install for glove-python: started\n",
      "    Running setup.py install for glove-python: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\niranjans3ln\\\\AppData\\\\Local\\\\Temp\\\\pip-install-ydr7ifc7\\\\glove-python_967621288cb94b3389cdbf0335aa4ca8\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\niranjans3ln\\\\AppData\\\\Local\\\\Temp\\\\pip-install-ydr7ifc7\\\\glove-python_967621288cb94b3389cdbf0335aa4ca8\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\niranjans3ln\\AppData\\Local\\Temp\\pip-record-hcior3be\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Anaconda3\\Include\\glove-python' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "#!pip install glove_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aaAVwfqHVM3I"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'glove'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word2Vec,FastText\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtest\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tmpfile\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mglove\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Glove, Corpus\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'glove'"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec,FastText\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from glove import Glove, Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "he0V2e8PYFpy"
   },
   "source": [
    "### **Word2Vec model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n82GYprkVU_U"
   },
   "outputs": [],
   "source": [
    "for cluster in range(10):\n",
    "  #Preparing parameters for model training\n",
    "  exec('corpus = sent_{}'.format(cluster))\n",
    "  vector_size = 100\n",
    "  w = 6\n",
    "  min_count = 5\n",
    "  CBoW = 0\n",
    "  iterations = 100\n",
    "\n",
    "  #Training Word2Vec model for each cluster\n",
    "  exec ('w2vmodel{} = Word2Vec(corpus, size=vector_size, window=w, min_count=min_count, sg=CBoW, iter=iterations)'.format(cluster))\n",
    "\n",
    "  #Save the all the models in individual file\n",
    "  exec('path = get_tmpfile(\"dataset/word2vec{}.model\")'.format(cluster))\n",
    "  exec('w2vmodel{}.save(\"dataset/word2vec{}.model\")'.format(cluster), cluster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dqxoHhzCZIVi"
   },
   "source": [
    "### **FastText model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "_g6HDHEylpRh",
    "outputId": "33629426-000f-476f-e4b8-4b60dc34a747"
   },
   "outputs": [],
   "source": [
    "for cluster in range(10):\n",
    "  #Preparing parameters for model training\n",
    "  exec('corpus = sent_{}'.format(cluster))\n",
    "  vector_size = 100\n",
    "  w = 6\n",
    "  min_count = 5\n",
    "  CBoW = 0\n",
    "  iterations = 100\n",
    "\n",
    "  #Training FastText model for each cluster\n",
    "  exec ('ftmodel{} = FastText(corpus, size=vector_size, window=w, min_count=min_count, sg=CBoW, iter=iterations)'.format(cluster))\n",
    "\n",
    "  #Save the all the models in individual file\n",
    "  exec('path = get_tmpfile(\"dataset/ftmodel{}.model\")'.format(cluster))\n",
    "  exec('ftmodel{}.save(\"dataset/ftmodel{}.model\")'.format(cluster, cluster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kCdnHdsUc3Dm"
   },
   "source": [
    "### **GloVe model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjqrrgitqHgX"
   },
   "outputs": [],
   "source": [
    "#Training GloVe model for each cluster\n",
    "for cluster in range(10):\n",
    "  vector_size = 100\n",
    "  exec('glove_corpus{}=Corpus()'.format(cluster, cluster)) \n",
    "  exec('glove_corpus{}.fit(sent_{})'.format(cluster, cluster))\n",
    "  exec('glove{}= Glove(no_components=vector_size, learning_rate=0.18, alpha=0.75, max_count=100, max_loss=10.0, random_state=None)'.format(cluster, cluster))\n",
    "  exec('glove{}.fit(glove_corpus{}.matrix, epochs=1000, no_threads=3, verbose=True)'.format(cluster, cluster))\n",
    "  exec('transformer = lambda dictionary2:glove{}.transform_paragraph(words, epochs=1000,ignore_missing=False)'.format(cluster, cluster))\n",
    "  exec('glove{}.add_dictionary(glove_corpus{}.dictionary)'.format(cluster, cluster))\n",
    "\n",
    "  #Save the all the models in individual file\n",
    "  exec('path = get_tmpfile(\"dataset/glove{}.model\")'.format(cluster))\n",
    "  exec('glove{}.save(\"dataset/glove{}.model\")'.format(cluster, cluster))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "feature_extration_model_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
